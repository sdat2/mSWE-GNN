# adforce_config.yaml
#
# Hyperparameters for the Adforce/SWE-GNN pipeline.
#
# NOTE: Scaling statistics (mean/std) are no longer stored here.
# They are automatically computed from the training files and saved in
# 'data_processed/train/scaling_stats.yaml' by adforce_main.py.

# -----------------------------------------------------------------------------
# Data Loading Parameters (for adforce_main.py and AdforceLazyDataset)
# -----------------------------------------------------------------------------
data_params:
  # Path to the directory containing all simulation *.nc files
  data_dir: "/Volumes/s/tcpips/swegnn_5sec/"

  # Split ratio for validation set (from adforce_main.py)
  test_size: 0.2
  random_state: 42

  # Number of *input* time steps to provide to the model
  # This is the 'previous_t' argument for AdforceLazyDataset
  #
  previous_t: 1

  # Number of CPU workers for the DataLoader
  num_workers: 0

# -----------------------------------------------------------------------------
# Model Parameters (for GNNModel_new, MSGNNModel_new, or MLPModel_new)
# -----------------------------------------------------------------------------
model_params:
  # 'GNN' for GNNModel_new
  # 'MSGNN' for MSGNNModel_new
  # 'MLP' for MLPModel_new (baseline)
  #
  model_type: GNN

  # --- Common Hyperparameters (used by GNN, MSGNN, and MLP) ---
  #
  hid_features: 64
  mlp_layers: 2
  mlp_activation: 'prelu' # 'relu', 'prelu', 'tanh'
  
  # --- GNN-specific parameters ---
  # (Only used if model_type is 'GNN' or 'MSGNN')
  #
  type_gnn: 'GCN'         # Options: 'GCN', 'SAGE', 'GIN', 'GAT'
  gnn_activation: 'tanh'  # 'relu', 'prelu', 'tanh'

  # --- MSGNN-specific parameters ---
  # (Only used if model_type is 'MSGNN')
  #
  num_scales: 3
  learned_pooling: false
  skip_connections: true

# -----------------------------------------------------------------------------
# Trainer Options (for LightningTrainer)
# -----------------------------------------------------------------------------
trainer_options:
  # Batch size (also used by DataModule in adforce_main.py)
  batch_size: 2

  # Loss function type: 'RMSE' or 'MAE'
  #
  type_loss: 'RMSE'

  # Whether to only compute loss where water depth (target) > 0.01
  # This now uses the 'y_unscaled' variable from the dataset
  only_where_water: true

  # Weighting factor for velocity components (VX, VY) in the loss
  velocity_scaler: 5.0

# -----------------------------------------------------------------------------
# Learning Rate Scheduler (for LightningTrainer)
# -----------------------------------------------------------------------------
lr_info:
  #
  learning_rate: 0.001
  weight_decay: 0.0001
  step_size: 20  # num epochs before decaying LR
  gamma: 0.5     # decay factor

# -----------------------------------------------------------------------------
# Lightning Trainer Parameters (for L.Trainer in adforce_main.py)
# -----------------------------------------------------------------------------
lightning_trainer:
  max_epochs: 50
  # accelerator: "gpu"
  # devices: 1
  start_from_checkpoint_path: /Volumes/s/tcpips/mSWE-GNN/checkpoints/GNN/GNN-best-epoch=14-val_loss=0.8840.ckpt # null <-- (This is the default)