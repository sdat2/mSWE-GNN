# conf/config.yaml
defaults:
  - machine: mac # Default to mac paths
  - _self_

# Hydra settings
hydra:
  run:
    # {machine.root_dir}/outputs/{now:%Y-%m-%d}/{now:%H-%M-%S}
    dir: ${machine.output_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${machine.output_dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

# Group for machine-specific paths
machine:
  data_dir: ???
  processed_dir: "data_processed"
  output_dir: "outputs"
  checkpoint_dir: "checkpoints"
  resume_checkpoint_path: null # (e.g., /path/to/specific.ckpt)

# W&B settings
wandb:
  project: mswegnn
  entity: sdat2
  log_model: true

# --- Centralized Feature Definition ---
features:
  # Static node features from NetCDF.
  # 'node_type' is added automatically by the dataset from 'face_BC'.
  static:
    - DEM
    - slopex
    - slopey
    - area

  # --- NEW: Static edge features from NetCDF ---
  # These are now configurable for ablation.
  edge:
    - face_distance
    - edge_slope

  # Dynamic forcing features from NetCDF.
  forcing:
    - WX
    - WY
    - P

  # State variables from NetCDF. Used for y(t) input and target calculation.
  state:
    - WD
    - VX
    - VY

  # Derived state features, calculated on-the-fly by the dataset.
  # 'name': The new feature name.
  # 'op': The operation to perform (must be implemented in AdforceLazyDataset.get)
  # 'args': List of vars to use. Can mix 'static' and 'state' vars.
  derived_state:
    - { name: 'SSH', op: 'subtract', args: ['WD', 'DEM'] }
    # e.g., - { name: 'V_mag', op: 'magnitude', args: ['VX', 'VY'] }

  # Target variables. The model predicts the delta of these.
  # This MUST match the 'state' list for the current delta-learning setup.
  targets:
    - WD
    - VX
    - VY

# --- data_params ---
data_params:
  # --- MODE 1: RANDOM SPLIT ---
  # These are used if 'split_files' section below is null.
  held_out_test_size: 0.2
  test_size: 0.2  # This is the validation size (relative to train+val)
  random_state: 42
  # Move hard-coded Katrina file here
  manual_test_holdout: "152_KATRINA_2005.nc" 

  # --- MODE 2: EXPLICIT SPLIT FILES ---
  # If paths are provided, these files will be used *instead* # of the random split. Paths can be relative to your run directory.
  # The files should contain one .nc filename per line (e.g., "262_GILBERT_1988.nc")
  split_files:
    train: null   # e.g., "conf/splits/train_files.txt"
    val: null     # e.g., "conf/splits/val_files.txt"
    test: null    # e.g., "conf/splits/test_files.txt"

  # --- Other params ---
  num_workers: 4

# --- model_params ---
model_params:
  previous_t: 1       # Number of history steps for model input
  model_type: GNN
  hid_features: 64
  mlp_layers: 2
  mlp_activation: 'prelu'
  type_gnn: 'GCN'
  gnn_activation: 'tanh'
  K: 3
  normalize: true
  with_gradient: true
  edge_mlp: true

# --- Unchanged ---
trainer_options:
  batch_size: 2
  type_loss: 'RMSE'
  only_where_water: true
  velocity_scaler: 5.0

lr_info:
  learning_rate: 0.001
  weight_decay: 0.0001
  step_size: 20
  gamma: 0.5

lightning_trainer:
  max_epochs: 100
  #accelerator: "gpu"
  # devices: 1