import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt
from torch_geometric.utils import scatter
from wandb import Config

from mswegnn.database.graph_creation import MultiscaleMesh
from mswegnn.utils.dataset import (
    to_temporal_dataset,
    get_inflow_volume,
    create_scale_mask,
)
from mswegnn.training.loss import conservation_loss, mask_on_water, get_mean_error
from mswegnn.models.gnn import GNN, MSGNN

NUM_WATER_VARS = 3  # water depth and discharge


def get_model(model_name):
    models_dict = {"GNN": GNN, "MSGNN": MSGNN}
    return models_dict[model_name]


def get_time_vector(total_time_steps, temporal_res):
    """Returns array with temporal stamps (from 0 to total_time in hours)"""
    total_hours = total_time_steps * temporal_res / 60
    time_vector = np.linspace(0, total_hours, total_time_steps + 1)
    return time_vector


def add_null_time_start(time_start, temporal_array):
    """Adds null values to the beginning of a temporal array

    time_start: int
        initial time of the simulation = number of null values to add
    temporal_array: np.array
        temporal array with dimensions [N_datasets, T] or [T]
    """
    if temporal_array.ndim == 1:  # [T]
        new_temporal_array = np.concatenate(
            (np.nan * np.empty(time_start + 1), temporal_array)
        )
    elif temporal_array.ndim == 2:  # [N_datasets, T]
        new_temporal_array = np.concatenate(
            (
                np.nan * np.empty((temporal_array.shape[0], time_start + 1)),
                temporal_array,
            ),
            axis=1,
        )
    else:
        raise ValueError("Wrong temporal array dimensions")

    return new_temporal_array


def get_velocity(discharge, water_depth, epsilon=0.01):
    velocity = discharge / water_depth
    low_water = water_depth <= epsilon
    velocity[low_water] = 0
    return velocity


def get_Froude(velocity, water_depth):
    g = 9.81
    froude = velocity / torch.sqrt(g * water_depth)
    froude[water_depth <= 0] = 0
    return froude


def WD_to_FAT(WD, temporal_res, water_threshold=0, time_start=0):
    """
    Creates flood arrival times map from temporal sequence of WD maps
    """
    assert WD.dim() == 2, "WD must be a tensor of dimension [N, T]"
    total_time = time_start + WD.shape[-1]

    flooded_areas = WD > water_threshold
    flooded_time = flooded_areas.sum(1)
    FAT = -(flooded_time - total_time)
    FAT_hours = FAT * temporal_res / 60

    return FAT_hours


def get_numerical_times(
    dataset_name,
    dataset_size,
    temporal_res,
    maximum_time,
    overview_file="database/raw_datasets/overview.csv",
    **temporal_test_dataset_parameters,
):

    time_start = temporal_test_dataset_parameters["time_start"]
    time_stop = temporal_test_dataset_parameters["time_stop"]

    final_time = time_stop % maximum_time + (time_stop == -1)

    assert final_time != -1, "I'm not sure how to interpret final_time value of -1"

    numerical_simulation_overview = pd.read_csv(overview_file, sep=",")

    mesh_dataset_train_id = numerical_simulation_overview["seed"].isin(np.arange(1, 80))
    mesh_dataset_test_id = numerical_simulation_overview["seed"].isin(
        np.arange(81, 101)
    )

    dijk15_train_id = numerical_simulation_overview["seed"].isin([101])
    dijk15_test_id = numerical_simulation_overview["seed"].isin(np.arange(102, 112))

    dataset_ids = {
        "mesh_dataset_train": mesh_dataset_train_id,
        "mesh_dataset_test": mesh_dataset_test_id,
        "multiscale_mesh_dataset_train": mesh_dataset_train_id,
        "multiscale_mesh_dataset_test": mesh_dataset_test_id,
        "dijkring_15_train": dijk15_train_id,
        "dijkring_15_test": dijk15_test_id,
    }

    ids = dataset_ids.get(dataset_name)
    if ids is None:
        raise ValueError("Wrong 'dataset_name' or maybe folder")

    computation_time = numerical_simulation_overview.loc[ids]["computation_time[s]"]

    simulated_times = numerical_simulation_overview.loc[ids]["simulation_time[h]"]
    model_simulated_times = (final_time - time_start) * temporal_res / 60

    time_ratio = model_simulated_times / simulated_times

    return (computation_time * time_ratio).iloc[:dataset_size]


def get_speed_up(numerical_times, model_times):
    """Calculate speed up as ratio between simulation time and DL model time"""
    speed_up = numerical_times / model_times

    return speed_up.mean(), speed_up.std()


def get_mass_conservation_loss(rollout, data):
    """Calculates mass conservation loss for a given simulation"""
    data.area = data.area[data.node_ptr[0] : data.node_ptr[1]]
    return torch.stack(
        [
            conservation_loss(
                rollout[:, 0::NUM_WATER_VARS, t],
                rollout[:, 0::NUM_WATER_VARS, t - 1],
                data,
                (data.BC[:, t] + data.BC[:, t + 1]) / 2,
            )
            for t in range(1, rollout.shape[-1])
        ]
    )


def get_binary_rollouts(predicted_rollout, real_rollout, water_threshold=0):
    """Converts flood simulation into a binary map (1=flood, 0=no flood) for classification purposes
    ------
    water_threshold: float
        Threshold for the binary map creation, i.e., 'flood' if WD>threshold
    """
    if predicted_rollout.dim() == 4:
        predicted_rollout_flood = predicted_rollout[:, :, 0, :] > water_threshold
        real_roll_flood = real_rollout[:, :, 0, :] > water_threshold
    elif predicted_rollout.dim() == 3:
        predicted_rollout_flood = predicted_rollout[:, 0, :] > water_threshold
        real_roll_flood = real_rollout[:, 0, :] > water_threshold

    return predicted_rollout_flood, real_roll_flood


def get_rollout_confusion_matrix(predicted_rollout, real_rollout, water_threshold=0):
    predicted_rollout_flood, real_roll_flood = get_binary_rollouts(
        predicted_rollout, real_rollout, water_threshold=water_threshold
    )

    if predicted_rollout.dim() == 4:
        nodes_dim = 1
    elif predicted_rollout.dim() == 3:
        nodes_dim = 0

    TP = (predicted_rollout_flood & real_roll_flood).sum(nodes_dim)  # true positive
    TN = (~predicted_rollout_flood & ~real_roll_flood).sum(nodes_dim)  # true negative
    FP = (predicted_rollout_flood & ~real_roll_flood).sum(nodes_dim)  # false positive
    FN = (~predicted_rollout_flood & real_roll_flood).sum(nodes_dim)  # false negative

    return TP, TN, FP, FN


def get_CSI(predicted_rollout, real_rollout, water_threshold=0):
    """Returns the Critical Success Index (CSI) in time for a given water_threshold"""
    TP, TN, FP, FN = get_rollout_confusion_matrix(
        predicted_rollout, real_rollout, water_threshold=water_threshold
    )

    CSI = TP / (TP + FN + FP)
    # CSI[torch.isnan(CSI)] = 0

    return CSI


def get_F1(predicted_rollout, real_rollout, water_threshold=0):
    """Returns the Critical Success Index (CSI) in time for a given water_threshold"""
    TP, TN, FP, FN = get_rollout_confusion_matrix(
        predicted_rollout, real_rollout, water_threshold=water_threshold
    )

    F1 = TP / (TP + 0.5 * (FN + FP))
    # F1[torch.isnan(F1)] = 0

    return F1


def get_masked_diff(diff_roll, where_water):
    masked_diff = torch.stack(
        [
            diff_roll[:, water_variable, :][where_water]
            for water_variable in range(diff_roll.shape[1])
        ]
    )

    return masked_diff


def get_rollout_loss(
    predicted_rollout, real_rollout, type_loss="RMSE", only_where_water=False
):
    diff_roll = predicted_rollout - real_rollout

    if diff_roll.dim() == 4:  # multiple simulations
        nodes_dim = 1
        water_axis = 2
    elif diff_roll.dim() == 3:  # single simulation
        nodes_dim = 0
        water_axis = 1

    if only_where_water:
        where_water = mask_on_water(diff_roll, water_axis=water_axis)

        if diff_roll.dim() == 4:
            roll_loss = torch.stack(
                [
                    get_mean_error(
                        get_masked_diff(diff_roll[id_dataset], where_water[id_dataset]),
                        type_loss,
                        nodes_dim=-1,
                    )
                    for id_dataset in range(diff_roll.shape[0])
                ]
            )
        elif diff_roll.dim() == 3:
            roll_loss = get_mean_error(
                get_masked_diff(diff_roll, where_water), type_loss, nodes_dim=-1
            )
    else:
        roll_loss = get_mean_error(diff_roll, type_loss, nodes_dim=nodes_dim).mean(-1)

    return roll_loss


def plot_line_with_deviation(
    time_vector, variable, with_minmax=False, ax=None, **plt_kwargs
):
    """Plots a line with mean and standard deviation
    ------
    time_vector: np.array
        vector with time stamps [h]
    variable: np.array
        vector with the variable to plot
    with_minmax: bool
        If True, also plots the envelope of the minimum and maximum values
    """
    ax = ax or plt.gca()

    df = pd.DataFrame(np.vstack((time_vector, variable))).T
    df = df.rename(columns={0: "time"})
    df = df.set_index("time")

    mean = df.mean(1)
    std = df.std(1)
    under_line = mean - std
    over_line = mean + std

    p = ax.plot(mean, linewidth=2, marker="o", **plt_kwargs)
    color = p[0].get_color()
    ax.fill_between(std.index, under_line, over_line, color=color, alpha=0.3)
    if with_minmax:
        ax.plot(df.min(1), color=color, linestyle="--", alpha=0.5)
        ax.plot(df.max(1), color=color, linestyle="--", alpha=0.5)
    return p


def fix_dict_in_config(wandb):
    config = dict(wandb.config)
    for k, v in config.copy().items():
        if "." in k:
            new_key = k.split(".")[0]
            inner_key = k.split(".")[1]
            if new_key not in config.keys():
                config[new_key] = {}
            config[new_key].update({inner_key: v})
            del config[k]

    wandb.config = Config()
    for k, v in config.items():
        wandb.config[k] = v


def get_pareto_front(df, objective_function1, objective_function2, ascending=False):
    """Returns the pareto front of a dataframe with two objective functions

    df: pd.DataFrame
        Dataframe with the objective functions
    objective_function1: str
        Name of the first objective function
    objective_function2: str
        Name of the second objective function
    ascending: bool
        If True, the pareto front is calculated for ascending values of the objective functions
    """
    sorted_df = df.sort_values(
        by=[objective_function1, objective_function2], ascending=ascending
    )[[objective_function1, objective_function2]]

    pareto_front = sorted_df.values[0].reshape(1, -1)
    for var1, var2 in sorted_df.values[1:]:
        if var2 >= pareto_front[-1, 1]:
            pareto_front = np.concatenate(
                (pareto_front, np.array([[var1, var2]])), axis=0
            )

    return pareto_front


def get_sufficient_k_hops(edge_index, WD, cover_percentage=0.999):
    """Determine how many K-hops are needed to cover the cells changed in one time step

    cover_percentage: float
        Percentage of cells that need to be covered by the GNN k-hops
    """
    assert (
        WD.dim() == 2
    ), "The input WD matrix should contain the full original simulation [NxT]"

    row = edge_index[0]
    col = edge_index[1]

    num_nodes = WD.shape[0]
    time_steps = WD.shape[1]
    water_t1 = torch.stack([WD[:, t] > 0 for t in range(1, time_steps)]).T

    fake_water = torch.zeros_like(WD)
    fake_water[WD > 0] = 1
    fake_water = fake_water[:, :-1]

    changes_fully_covered = (fake_water[water_t1] > 0).all()

    k = 0
    while not changes_fully_covered:
        fake_water = (
            scatter(fake_water[row], col, reduce="sum", dim=0, dim_size=num_nodes)
            + fake_water
        )
        fake_water[fake_water > 0] = 1
        changes_fully_covered = (fake_water[water_t1] > 0).all()
        if cover_percentage < 1:
            changes_fully_covered = (
                fake_water[water_t1] > 0
            ).sum() > cover_percentage * water_t1.sum()
        else:
            changes_fully_covered = (fake_water[water_t1] > 0).all()
        k += 1
        if k > 50:
            print("This number of k-hops is probably wrong")
            break

    return k


def get_sufficient_k_hops_per_scale(
    edge_index, WD, edge_ptr, node_ptr, cover_percentage=0.999
):
    """Determine how many K-hops are needed to cover the cells changed in one time step at the different scales"""

    khop_per_scale = [
        get_sufficient_k_hops(
            edge_index[:, edge_ptr[i] : edge_ptr[i + 1]] - node_ptr[i],
            WD[node_ptr[i] : node_ptr[i + 1]],
            cover_percentage,
        )
        for i in range(len(node_ptr) - 1)
    ]
    return khop_per_scale


class SpatialAnalysis:
    def __init__(
        self,
        predicted_rollout,
        prediction_times,
        dataset,
        **temporal_test_dataset_parameters,
    ):
        self.dataset = [data.cpu() for data in dataset]
        self.time_start = temporal_test_dataset_parameters["time_start"]
        self.time_stop = temporal_test_dataset_parameters["time_stop"]
        self.temporal_res = dataset[0].temporal_res
        self.DEMs = self._get_DEMS(self.dataset)
        temporal_dataset = to_temporal_dataset(
            dataset, rollout_steps=-1, **temporal_test_dataset_parameters
        )
        self.real_rollout = [data.y for data in temporal_dataset]
        self.predicted_rollout = predicted_rollout
        self.prediction_times = prediction_times
        if isinstance(self.dataset[0].mesh, MultiscaleMesh):
            self.BCs = torch.stack(
                [data.BC[0] for data in self.dataset]
            )  # only finest scale
            masks = [
                create_scale_mask(
                    data.num_nodes, data.mesh.num_meshes, data.node_ptr, data
                )
                == 0
                for data in self.dataset
            ]

            self.real_rollout = [
                real[masks[i]] for i, real in enumerate(self.real_rollout)
            ]
            self.predicted_rollout = [
                pred[masks[i]] for i, pred in enumerate(self.predicted_rollout)
            ]
        else:
            self.BCs = torch.cat([data.BC for data in self.dataset])
        self.type_BCs = [data.type_BC.item() for data in self.dataset]
        total_time_steps = self.real_rollout[0].shape[-1] + self.time_start
        self.time_vector = get_time_vector(total_time_steps, self.temporal_res)

    def _get_DEMS(self, dataset):
        if isinstance(dataset, list):
            DEMs = [data.DEM for data in dataset]
        else:
            DEMs = dataset.DEM
        return DEMs

    def _plot_metric_rollouts(
        self, metric_name, metric_function, water_thresholds=[0.05, 0.3], ax=None
    ):
        """Plots metric in time for different water_thresholds
        -------
        metric_function:
            options: get_CSI, get_F1
        """
        if ax is None:
            fig, ax = plt.subplots(figsize=(7, 5))

        all_metric = []
        for wt in water_thresholds:
            metric = (
                torch.stack(
                    [
                        metric_function(pred, real, water_threshold=wt)
                        for pred, real in zip(self.predicted_rollout, self.real_rollout)
                    ]
                )
                .to("cpu")
                .numpy()
            )
            all_metric.append(metric)
            metric = add_null_time_start(self.time_start, metric)
            plot_line_with_deviation(
                self.time_vector, metric, ax=ax, label=f"{metric_name}$_{{{wt}}}$"
            )
            # plt.legend()

        ax.set_xlabel("Time [h]")
        ax.set_title(f"{metric_name} score")
        ax.set_ylim(0, 1)
        ax.grid()
        ax.legend(loc=4)

        return ax, np.array(all_metric)

    def _plot_rollouts(self, type_loss, ax=None):
        """Plots loss in time for the different water variables"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(7, 5))

        water_labels = ["h [m]", "|q| [$m^2$/s]"]
        var_colors = ["royalblue", "purple"]
        lines = []

        ax2 = ax.twinx()
        axx = ax

        diff_rollout = torch.stack(
            [
                get_mean_error(pred - real, type_loss, nodes_dim=0)
                for pred, real in zip(self.predicted_rollout, self.real_rollout)
            ]
        )

        for var in range(diff_rollout.shape[1]):
            average_diff_t = diff_rollout[:, var, :].to("cpu").numpy()
            average_diff_t = add_null_time_start(self.time_start, average_diff_t)
            lines.append(
                plot_line_with_deviation(
                    self.time_vector,
                    average_diff_t,
                    ax=axx,
                    label=water_labels[var],
                    c=var_colors[var],
                )[0]
            )
            axx = ax2

        ax.tick_params(axis="y", colors="royalblue")
        ax2.tick_params(axis="y", colors=lines[var].get_color())
        axx = ax
        ax.set_xlabel("Time [h]")
        ax.set_title(type_loss)

        labs = [l.get_label() for l in lines]
        ax.legend(lines, labs, loc=2)

        return ax

    def _plot_BCs(self, ax=None):
        """Plots boundary conditions in time"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(7, 5))

        type_BC_dict = {1: "Water depth [m]", 2: "Discharge [$m^3$/s]"}

        if isinstance(self.dataset[0].mesh, MultiscaleMesh):
            cell_length = torch.tensor(
                [data.edge_BC_length[0].cpu() for data in self.dataset]
            )  # only finest scale
        else:
            cell_length = torch.cat(
                [data.edge_BC_length.cpu() for data in self.dataset]
            )
        inflow_nodes = (self.BCs.T * cell_length).T

        time_vector = get_time_vector(inflow_nodes.shape[-1] - 1, self.temporal_res)
        plot_line_with_deviation(
            time_vector,
            inflow_nodes.cpu(),
            with_minmax=True,
            label=f"{type_BC_dict[self.type_BCs[0]]}",
        )

        ax.set_xlabel("Time [h]")
        ax.set_ylabel(f"{type_BC_dict[self.type_BCs[0]]}")
        ax.set_title("Boundary conditions")
        ax.grid()
        # ax.legend(loc=1)

        return ax

    def _get_CSI(self, water_threshold=0):
        CSI = [
            get_CSI(pred, real, water_threshold=water_threshold)
            for pred, real in zip(self.predicted_rollout, self.real_rollout)
        ]
        return torch.stack(CSI)

    def _get_F1(self, water_threshold=0):
        F1 = [
            get_F1(pred, real, water_threshold=water_threshold)
            for pred, real in zip(self.predicted_rollout, self.real_rollout)
        ]
        return torch.stack(F1)

    def plot_CSI_rollouts(self, water_thresholds=[0.05, 0.3], ax=None):
        return self._plot_metric_rollouts(
            "CSI", get_CSI, water_thresholds=water_thresholds, ax=ax
        )

    def plot_F1_rollouts(self, water_thresholds=[0.05, 0.3], ax=None):
        return self._plot_metric_rollouts(
            "F1", get_F1, water_thresholds=water_thresholds, ax=ax
        )

    def _get_mass_loss_in_time(self):
        mass_loss = (
            torch.stack(
                [
                    get_mass_conservation_loss(self.predicted_rollout[i], data.cpu())
                    for i, data in enumerate(self.dataset)
                ]
            )
            * 1e6
        )  # denormalize
        return mass_loss

    def plot_mass_conservation(self):
        """Plots mass conservation in time for one or more simulations"""
        fig, ax = plt.subplots(figsize=(7, 5))

        mass_loss = self._get_mass_loss_in_time().cpu().numpy()
        mass_loss = add_null_time_start(self.time_start + 1, mass_loss)

        inflow_volume = torch.tensor(
            [
                [
                    get_inflow_volume(data, data.BC[:, t : t + 2].mean(1))
                    for t in range(mass_loss.shape[1] - 1)
                ]
                for data in self.dataset
            ]
        )

        inflow_volume = add_null_time_start(self.time_start, inflow_volume)
        # cum_mass_loss = np.nancumsum(mass_loss, axis=-1)
        # cum_mass_loss_norm = cum_mass_loss/np.nancumsum(inflow_volume.mean(0), axis=-1)

        plot_line_with_deviation(
            self.time_vector, inflow_volume, label="Inflow volume", ax=ax
        )
        plot_line_with_deviation(self.time_vector, mass_loss, label="Error", ax=ax)

        ax.legend()
        ax.set_xlabel("Time [h]")
        ax.set_ylabel("Volume per time step [$m^3$]")

        plt.tight_layout()

        return mass_loss

    def _get_rollout_loss(self, type_loss="RMSE", only_where_water=False):
        rollout_losses = [
            get_rollout_loss(
                pred, real, type_loss=type_loss, only_where_water=only_where_water
            )
            for pred, real in zip(self.predicted_rollout, self.real_rollout)
        ]

        return torch.stack(rollout_losses)

    def plot_loss_per_simulation(
        self,
        type_loss="RMSE",
        water_thresholds=[0.05, 0.3],
        ranking="loss",
        only_where_water=False,
        figsize=(20, 12),
    ):
        """Plot sorted loss for each simulation in a dataset
        ranking: criterion to sort simulations
            options: 'loss', 'CSI'
        """
        rollout_loss = self._get_rollout_loss(
            type_loss=type_loss, only_where_water=only_where_water
        )
        CSIs = (
            torch.stack([self._get_CSI(wt) for wt in water_thresholds], 1)
            .nanmean(2)
            .to("cpu")
        )

        assert rollout_loss.dim() == 2, (
            "rollout_loss should have dimension [S, O]"
            "where S is the number of simulations and O is the output dimension"
        )
        if rollout_loss.shape[0] == 1:
            raise ValueError("This plot works only for multiple simulations")
        if isinstance(rollout_loss, torch.Tensor):
            rollout_loss = rollout_loss.to("cpu").numpy()

        fig, axs = plt.subplots(3, 1, figsize=figsize, sharex="col")

        if ranking == "loss":
            sorted_ids = rollout_loss.mean(1).argsort()
        elif ranking == "CSI":
            sorted_ids = CSIs.mean(1).argsort().flip(-1).numpy()
        else:
            raise ValueError("ranking can only be either 'loss' or 'CSI'")

        positions = range(len(sorted_ids))

        water_variables = rollout_loss.shape[1]
        if water_variables == 1:
            water_labels = ["h [m]"]
            var_colors = ["royalblue"]
        elif water_variables == 2:
            water_labels = ["h [m]", "|q| [$m^2$/s]"]
            var_colors = ["royalblue", "purple"]
        elif water_variables == 3:
            water_labels = ["h [m]", "qx [$m^2$/s]", "qy [$m^2$/s]"]
            var_colors = ["royalblue", "orange", "darkgreen"]

        axs[0].set_title(f"{ranking} ranking for test simulations")
        n_x_ticks = range(len(sorted_ids))
        axs[0].boxplot([self.DEMs[i] for i in sorted_ids], positions=positions)
        axs[0].set_ylabel(r"DEM [m]")

        for i, (color, label) in enumerate(zip(var_colors, water_labels)):
            axs[1].plot(rollout_loss[sorted_ids, i], "o--", label=label, c=color)
        axs[1].set_ylabel(type_loss)
        axs[1].set_yscale("log")
        axs[1].legend()

        axs[2].set_xticks(n_x_ticks)
        axs[2].set_xticklabels(sorted_ids)

        [
            axs[2].plot(CSIs[sorted_ids, i], "o--", label=f"CSI$_{{{wt}}}$")
            for i, wt in enumerate(water_thresholds)
        ]
        axs[2].set_ylim(0, 1)
        axs[2].set_xlabel("Simulation id")
        axs[2].set_ylabel("CSI")
        axs[2].legend()

        fig.subplots_adjust(wspace=0, hspace=0.05)

        return sorted_ids

    def plot_summary(
        self,
        numerical_times,
        type_loss="RMSE",
        water_thresholds=[0.05, 0.3],
        only_where_water=False,
        figsize=(10, 5),
    ):

        fig, axs = plt.subplots(1, 3, figsize=figsize)

        RMSE = self._get_rollout_loss(
            type_loss=type_loss, only_where_water=only_where_water
        ).cpu()
        CSIs = [self._get_CSI(wt).nanmean(1).cpu() for wt in water_thresholds]

        axs[0].boxplot(CSIs)
        axs[0].set_ylim(0, 1)
        axs[0].set_xticklabels([r"$\tau$" f"={wt}m" for wt in water_thresholds])
        axs[0].set_title(r"CSI$_\tau$ [-]")

        axs[1].boxplot((RMSE[:, 0], RMSE[:, 1:].mean(1)))
        axs[1].set_xticklabels(("h [m]", "|q| [$m^2$/s]"))
        axs[1].set_title(f"{type_loss}")
        axs[1].set_yscale("log")

        axs[2].boxplot((self.prediction_times, numerical_times))
        axs[2].set_title("Execution times [sec]")
        axs[2].set_xticklabels(("DL", "Numerical"))
        axs[2].set_ylim(0)

        plt.tight_layout()

        return fig
