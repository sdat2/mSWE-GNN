# Libraries
import torch
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from mswegnn.database.graph_creation import MultiscaleMesh

def get_none_scalers():
    none_scalers = {'DEM_scaler'        : None,
                    'slope_scaler'      : None,
                    'area_scaler'       : None,
                    'edge_length_scaler': None,
                    'edge_slope_scaler' : None,
                    'WD_scaler'         : None,
                    'V_scaler'          : None}
    return none_scalers

def stack_attributes(dataset, attribute, inverse=False, to_min=False):
    '''
    Returns a vector containing all features 'attribute' contained in dataset
    '''
    if inverse:
        stacked_map = torch.cat([1/data[attribute] for data in dataset])
    else:
        stacked_map = torch.cat([data[attribute] - data[attribute].min()*to_min for data in dataset])

    return stacked_map.reshape(-1,1)

def scaler(train_database, attribute, type_scaler='minmax', inverse=False, to_min=False):
    '''
    Returns Scaler for a 2D map
    This function should consider only the training dataset
    -------
    train_database : list
        each element in the list is a torch_geometric.data.data.Data object
    attribute: str or list or tuple
        name of the feature to be scaled
        if list, scaling applies to more features
        if tuple, elements are used for vector norm
    type_scaler: str
        name of the scaler
        options: 'minmax', 'minmax_neg', or 'standard'
    to_min: bool
        subtract the minimum value before scaling (then the minimum is always 0)
    '''
    assert isinstance(train_database, list), 'train_database must be a list of torch_geometric.data.data.Data objects'

    if type_scaler == 'minmax':
        scaler = MinMaxScaler(feature_range=(0,1))
    elif type_scaler == 'minmax_neg':
        scaler = MinMaxScaler(feature_range=(-1,1))
    elif type_scaler == 'standard':
        scaler = StandardScaler()
    elif type_scaler is None:
        return None
    else:
        raise 'type_scaler can be only "minmax", "minmax_neg", or "standard"'

    if isinstance(attribute, list):
        all_attrs = torch.cat([stack_attributes(train_database, attr, inverse=inverse, to_min=to_min) for attr in attribute])
    elif isinstance(attribute, tuple):
        all_attrs = torch.cat([stack_attributes(train_database, attr, inverse=inverse, to_min=to_min)**2 for attr in attribute], 1)
        all_attrs = all_attrs.sum(1).sqrt().reshape(-1,1)
    else:
        all_attrs = stack_attributes(train_database, attribute, inverse=inverse, to_min=to_min)

    scaler.fit(all_attrs)

    return scaler

def multiscale_scaler(train_database, attribute: str, type_feature:str, type_scaler='minmax'):
    '''
    Returns list of Scalers for a feature of the dataset, at each scale
    This function should consider only the training dataset and only multiscale datasets
    -------
    train_database : list
        each element in the list is a torch_geometric.data.data.Data object
    attribute: str
        name of the feature to be scaled
    type_feature: str
        'node' or 'edge' to indicate if the feature is defined at nodes or edges
    type_scaler: str
        name of the scaler
        options: 'minmax', 'minmax_neg', or 'standard'
    '''
    assert isinstance(train_database, list), 'train_database must be a list of torch_geometric.data.data.Data objects'
    assert isinstance(train_database[0].mesh, MultiscaleMesh), 'train_database must be a list of multiscale datasets'

    num_scales = train_database[0].mesh.num_meshes

    if type_scaler == 'minmax':
        scalers = [MinMaxScaler(feature_range=(0,1)) for _ in range(num_scales)]
    elif type_scaler == 'minmax_neg':
        scalers = [MinMaxScaler(feature_range=(-1,1)) for _ in range(num_scales)]
    elif type_scaler == 'standard':
        scalers = [StandardScaler() for _ in range(num_scales)]
    elif type_scaler is None:
        return None
    else:
        raise ValueError('type_scaler can be only "minmax", "minmax_neg", or "standard", instead got {}'.format(type_scaler) + ' for multiscale_scaler()')

    if type_feature == 'node':
        all_attrs = [torch.cat([data[attribute][data.node_ptr[i]:data.node_ptr[i+1]] for data in train_database]).reshape(-1,1) for i in range(num_scales)]
    elif type_feature == 'edge':
        all_attrs = [torch.cat([data[attribute][data.edge_ptr[i]:data.edge_ptr[i+1]] for data in train_database]).reshape(-1,1) for i in range(num_scales)]
    else:
        raise 'type_feature can be only "node" or "edge"'

    for attr, scaler in zip(all_attrs, scalers):
        scaler.fit(attr)

    return scalers

def get_scalers(dataset, scalers: dict):
    '''
    Returns scaler dictionary with scaler objects as values
    ------
    dataset: list
        training dataset used to obtain the scalers
    scalers: dict
        dict with the type of scaling used for every variable
        options: 'minmax', 'minmax_neg', 'standard', or None
    '''
    if scalers is None:
        scalers = get_none_scalers()

    scalers['DEM_scaler'] = scaler(dataset, 'DEM', type_scaler=scalers['DEM_scaler'], to_min=True)
    scalers['WD_scaler'] = scaler(dataset, 'WD', type_scaler=scalers['WD_scaler'])
    scalers['slope_scaler'] = scaler(dataset, ['slopex', 'slopey'], type_scaler=scalers['slope_scaler'])

    # for multiscale datasets use different scalers for area and edges
    if isinstance(dataset[0].mesh, MultiscaleMesh):
        scalers['area_scaler'] = multiscale_scaler(dataset, 'area', type_feature='node', type_scaler=scalers['area_scaler'])
        scalers['edge_length_scaler'] = multiscale_scaler(dataset, 'face_distance', type_feature='edge', type_scaler=scalers['edge_length_scaler'])
        scalers['edge_slope_scaler'] = multiscale_scaler(dataset, 'edge_slope', type_feature='edge', type_scaler=scalers['edge_slope_scaler'])
    else:
        scalers['area_scaler'] = scaler(dataset, 'area', type_scaler=scalers['area_scaler'], inverse=False)
        scalers['edge_length_scaler'] = scaler(dataset, 'face_distance', type_scaler=scalers['edge_length_scaler'])
        scalers['edge_slope_scaler'] = scaler(dataset, 'edge_slope', type_scaler=scalers['edge_slope_scaler'])

    scalers['V_scaler'] = scaler(dataset, ('VX', 'VY'), type_scaler=scalers['V_scaler'])

    return scalers
